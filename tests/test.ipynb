{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "https://github.com/opencv/opencv/blob/master/samples/python/find_obj.py\n",
      "https://www.pyimagesearch.com/2016/01/11/opencv-panorama-stitching/\n",
      "\n",
      "\n",
      "img1 - 337 features, img2 - 421 features\n",
      "8 / 36  inliers/matched\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "https://github.com/opencv/opencv/blob/master/samples/python/find_obj.py\n",
    "https://www.pyimagesearch.com/2016/01/11/opencv-panorama-stitching/\n",
    "\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "\n",
    "\n",
    "FLANN_INDEX_LSH    = 6\n",
    "\n",
    "\n",
    "def anorm2(a):\n",
    "    return (a*a).sum(-1)\n",
    "def anorm(a):\n",
    "    return np.sqrt( anorm2(a) )\n",
    "\n",
    "def matchKeypoints(keyPoints1, keyPoints2, descriptors1, descriptors2):\n",
    "\n",
    "    flann_params= dict(algorithm = FLANN_INDEX_LSH,\n",
    "                       table_number = 6, # 12\n",
    "                       key_size = 12,     # 20\n",
    "                       multi_probe_level = 1) #2\n",
    "\n",
    "\n",
    "\n",
    "    matcher = cv.FlannBasedMatcher(flann_params, {})  # bug : need to pass empty dict (#1329)\n",
    "    raw_matches = matcher.knnMatch(descriptors1, descriptors2, k = 2) #2\n",
    "\n",
    "    \n",
    "\n",
    "    matches = []\n",
    "    for m in raw_matches:\n",
    "        if len(m) == 2 and m[0].distance < m[1].distance * 0.79:\n",
    "            matches.append((m[0].trainIdx, m[0].queryIdx))\n",
    "\n",
    "\n",
    "    if len(matches) >= 4:\n",
    "\n",
    "        keyPoints1 = np.float32([keyPoints1[i] for (_, i) in matches])\n",
    "        keyPoints2 = np.float32([keyPoints2[i] for (i, _) in matches])\n",
    "\n",
    "\n",
    "        H, status = cv.findHomography(keyPoints1, keyPoints2, cv.RANSAC,4.0)\n",
    "\n",
    "        print('%d / %d  inliers/matched' % (np.sum(status), len(status)))\n",
    "    else:\n",
    "        H, status = None, None\n",
    "        print('%d matches found, not enough for homography estimation' % len(p1))\n",
    "\n",
    "\n",
    "    return matches, H, status\n",
    "\n",
    "\n",
    "   \n",
    "def drawMatches(image1, image2, keyPoints1, keyPoints2, matches, status):\n",
    "\n",
    "\n",
    "    h1, w1 = image1.shape[:2]\n",
    "    h2, w2 = image2.shape[:2]\n",
    "\n",
    "\n",
    "\n",
    "    img_matching_result = np.zeros((max(h1, h2), w1 + w2, 3), dtype=\"uint8\")\n",
    "\n",
    "\n",
    "\n",
    "    img_matching_result[0:h2, 0:w2] = image2\n",
    "    img_matching_result[0:h1, w2:] = image1\n",
    "\n",
    "\n",
    "\n",
    "    for ((trainIdx, queryIdx), s) in zip(matches, status):\n",
    "\n",
    "        if s == 1:\n",
    "            keyPoint2 = (int(keyPoints2[trainIdx][0]), int(keyPoints2[trainIdx][1]))\n",
    "            keyPoint1 = (int(keyPoints1[queryIdx][0]) + w2, int(keyPoints1[queryIdx][1]))\n",
    "            cv.line(img_matching_result, keyPoint1, keyPoint2, (0, 255, 0), 1)\n",
    "\n",
    "\n",
    "\n",
    "    return img_matching_result\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "\n",
    "    img1 = cv.imread('B.jpg') \n",
    "    img2 = cv.imread('A.jpg')\n",
    "    \n",
    "    \n",
    "\n",
    "    gray1 = cv.cvtColor(img1, cv.COLOR_BGR2GRAY)\n",
    "    gray2 = cv.cvtColor(img2, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "    \n",
    " \n",
    "    detector = cv.BRISK_create()\n",
    "    keyPoints1, descriptors1 = detector.detectAndCompute(gray1, None)\n",
    "    keyPoints2, descriptors2 = detector.detectAndCompute(gray2, None)\n",
    "    print('img1 - %d features, img2 - %d features' % (len(keyPoints1), len(keyPoints2)))\n",
    "\n",
    "\n",
    "    \n",
    "    keyPoints1 = np.float32([keypoint.pt for keypoint in keyPoints1])\n",
    "    keyPoints2 = np.float32([keypoint.pt for keypoint in keyPoints2])\n",
    "    \n",
    "\n",
    "\n",
    "    matches, H, status = matchKeypoints(keyPoints1, keyPoints2, descriptors1, descriptors2)\n",
    "\n",
    "\n",
    "\n",
    "    img_matching_result = drawMatches(img1, img2, keyPoints1, keyPoints2, matches, status)\n",
    "\n",
    "\n",
    "\n",
    "    result = cv.warpPerspective(img1, H,\n",
    "        (img1.shape[1] + img2.shape[1], img1.shape[0]))\n",
    "    result[0:img2.shape[0], 0:img2.shape[1]] = img2\n",
    "\n",
    "\n",
    "    cv.imshow('result', result)\n",
    "    cv.imshow('matching result', img_matching_result)\n",
    "\n",
    "    cv.waitKey()\n",
    "\n",
    "    print('Done')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(__doc__)\n",
    "    main()\n",
    "    cv.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
